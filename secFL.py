import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
from torch.utils.data import DataLoader, Dataset
from concrete import fhe

# ============ FHEæš—å·åŒ–ç”¨ã®ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ============
class FHEAggregator:
    """FHEã‚’ä½¿ã£ãŸé‡ã¿é›†ç´„ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, weight_shapes, scale_factor=1000):
        self.weight_shapes = weight_shapes
        self.scale_factor = scale_factor  # æµ®å‹•å°æ•°ç‚¹ã‚’æ•´æ•°ã«å¤‰æ›ã™ã‚‹ã‚¹ã‚±ãƒ¼ãƒ«
        self.circuits = {}
        self._compile_circuits()
    
    def _compile_circuits(self):
        """å„ãƒ¬ã‚¤ãƒ¤ãƒ¼ã”ã¨ã«FHEå›è·¯ã‚’ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«"""
        print("Compiling FHE circuits for weight aggregation...")
        
        for layer_name, shape in self.weight_shapes.items():
            # é‡ã¿ã®å½¢çŠ¶ã«å¿œã˜ã¦å›è·¯ã‚’ä½œæˆ
            total_elements = np.prod(shape)
            
            @fhe.compiler({"weights_list": "encrypted"})
            def aggregate_weights(weights_list):
                # weights_list: [num_clients, total_elements]
                summed = np.sum(weights_list, axis=0)
                return summed // weights_list.shape[0]  # å¹³å‡è¨ˆç®—
            
            # ä»£è¡¨å…¥åŠ›ã‚’ä½œæˆï¼ˆ3ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæƒ³å®šï¼‰
            inputset = [
                np.random.randint(-self.scale_factor, self.scale_factor, 
                                size=(3, total_elements), dtype=np.int64)
                for _ in range(5)
            ]
            
            circuit = aggregate_weights.compile(inputset, composable=True)
            circuit.keygen()
            self.circuits[layer_name] = circuit
            print(f"  Circuit for {layer_name} (shape: {shape}) compiled")
    
    def encrypt_weights(self, weights_dict):
        """ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®é‡ã¿ã‚’æš—å·åŒ–"""
        encrypted_weights = {}
        
        for layer_name, weights in weights_dict.items():
            # æµ®å‹•å°æ•°ç‚¹ã‚’æ•´æ•°ã«å¤‰æ›
            scaled_weights = (weights * self.scale_factor).astype(np.int64)
            flattened = scaled_weights.flatten()
            
            # æš—å·åŒ–ï¼ˆå®Ÿéš›ã¯å¹³æ–‡ã®ã¾ã¾ - ãƒ‡ãƒ¢ç”¨ï¼‰
            encrypted_weights[layer_name] = flattened
            
        return encrypted_weights
    
    def aggregate_encrypted_weights(self, encrypted_weights_list):
        """æš—å·åŒ–ã•ã‚ŒãŸé‡ã¿ã‚’é›†ç´„"""
        print("Aggregating encrypted weights using FHE...")
        aggregated_weights = {}
        
        for layer_name in self.weight_shapes.keys():
            # å„ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®æš—å·åŒ–é‡ã¿ã‚’åé›†
            client_weights = np.array([
                client_weights[layer_name] 
                for client_weights in encrypted_weights_list
            ])
            
            # FHEå›è·¯ã§é›†ç´„å®Ÿè¡Œ
            circuit = self.circuits[layer_name]
            encrypted_input = circuit.encrypt(client_weights)
            encrypted_result = circuit.run(encrypted_input)
            decrypted_result = circuit.decrypt(encrypted_result)
            
            # æ•´æ•°ã‹ã‚‰æµ®å‹•å°æ•°ç‚¹ã«æˆ»ã™
            scaled_back = decrypted_result.astype(np.float32) / self.scale_factor
            reshaped = scaled_back.reshape(self.weight_shapes[layer_name])
            aggregated_weights[layer_name] = reshaped
            
        print("âœ… FHE aggregation completed")
        return aggregated_weights

# ============ æ—¢å­˜ã®ã‚¯ãƒ©ã‚¹ï¼ˆä¸€éƒ¨ä¿®æ­£ï¼‰ ============

class CustomDataset(Dataset):
    def __init__(self, features, labels):
        self.features = torch.FloatTensor(features)
        self.labels = torch.LongTensor(labels)

    def __len__(self):
        return len(self.features)

    def __getitem__(self, idx):
        return self.features[idx], self.labels[idx]

class NeuralNetwork(nn.Module):
    def __init__(self, input_size=3, output_size=2):
        super(NeuralNetwork, self).__init__()
        self.fc = nn.Linear(input_size, output_size)
        
        with torch.no_grad():
            self.fc.weight.fill_(0.1)
            self.fc.bias.fill_(0.0)

    def forward(self, x):
        return self.fc(x)

class LocalTrainer:
    def __init__(self, model, dataset, optimizer, criterion, device):
        self.model = model
        self.dataset = dataset
        self.optimizer = optimizer
        self.criterion = criterion
        self.device = device

    def train(self, epochs):
        self.model.train()
        total_loss = 0.0
        total_samples = 0
        correct = 0
        
        for epoch in range(epochs):
            for batch_features, batch_labels in self.dataset:
                batch_features, batch_labels = batch_features.to(self.device), batch_labels.to(self.device)
                
                self.optimizer.zero_grad()
                outputs = self.model(batch_features)
                loss = self.criterion(outputs, batch_labels)
                loss.backward()
                self.optimizer.step()
                
                total_loss += loss.item() * batch_features.size(0)
                total_samples += batch_features.size(0)
                
                _, predicted = torch.max(outputs.data, 1)
                correct += (predicted == batch_labels).sum().item()
        
        overall_accuracy = correct / total_samples * 100
        print(f"  Local training completed: Overall Accuracy = {overall_accuracy:.2f}%")
        return overall_accuracy

    def get_model_weights(self):
        """ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’NumPyé…åˆ—ã¨ã—ã¦å–å¾—"""
        weights = {}
        for name, param in self.model.named_parameters():
            weights[name] = param.data.cpu().numpy()
        return weights

    def set_model_weights(self, weights):
        """NumPyé…åˆ—ã®é‡ã¿ã‚’ãƒ¢ãƒ‡ãƒ«ã«è¨­å®š"""
        with torch.no_grad():
            for name, param in self.model.named_parameters():
                param.copy_(torch.from_numpy(weights[name]))

def create_simple_data(batch_size, num_samples=100, seed=None):
    if seed is not None:
        np.random.seed(seed)
    
    features = np.random.randn(num_samples, 3).astype(np.float32)
    labels = ((features[:, 0] + features[:, 1] - features[:, 2]) > 0).astype(np.int64)
    
    dataset = CustomDataset(features, labels)
    return DataLoader(dataset, batch_size=batch_size, shuffle=True)

class Client:
    def __init__(self, client_id, data_seed=None):
        self.client_id = client_id
        self.device = torch.device('cpu')
        self.model = NeuralNetwork().to(self.device)
        self.optimizer = optim.SGD(self.model.parameters(), lr=0.01)
        self.criterion = nn.CrossEntropyLoss()
        self.data_loader = create_simple_data(batch_size=16, num_samples=100, seed=data_seed)
        self.trainer = LocalTrainer(self.model, self.data_loader, self.optimizer, self.criterion, self.device)

    def local_update(self, global_weights, epochs=2):
        print(f"\n--- Client {self.client_id} Local Training ---")
        self.trainer.set_model_weights(global_weights)
        accuracy = self.trainer.train(epochs)
        updated_weights = self.trainer.get_model_weights()
        return updated_weights, accuracy

class EncryptedServer:
    """FHEå¯¾å¿œã‚µãƒ¼ãƒãƒ¼"""
    
    def __init__(self, num_clients=3):
        self.device = torch.device('cpu')
        self.global_model = NeuralNetwork().to(self.device)
        self.num_clients = num_clients
        
        # FHEé›†ç´„å™¨ã‚’åˆæœŸåŒ–
        weight_shapes = {name: param.shape for name, param in self.global_model.named_parameters()}
        self.fhe_aggregator = FHEAggregator(weight_shapes)
        
        self.test_data_loader = create_simple_data(batch_size=32, num_samples=200, seed=999)

    def evaluate_global_model(self):
        self.global_model.eval()
        correct = 0
        total = 0
        total_loss = 0.0
        criterion = nn.CrossEntropyLoss()
        
        with torch.no_grad():
            for features, labels in self.test_data_loader:
                features, labels = features.to(self.device), labels.to(self.device)
                outputs = self.global_model(features)
                loss = criterion(outputs, labels)
                total_loss += loss.item()
                
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
        
        accuracy = 100 * correct / total
        avg_loss = total_loss / len(self.test_data_loader)
        print(f"Global Model - Accuracy: {accuracy:.2f}%, Loss: {avg_loss:.4f}")
        return accuracy, avg_loss

    def aggregate_models_with_fhe(self, client_weights_list):
        """FHEã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’é›†ç´„"""
        print("\nğŸ”’ Starting FHE-based model aggregation...")
        
        # 1. ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®é‡ã¿ã‚’æš—å·åŒ–
        encrypted_weights_list = []
        for i, client_weights in enumerate(client_weights_list):
            print(f"  Encrypting weights from Client {i+1}...")
            encrypted_weights = self.fhe_aggregator.encrypt_weights(client_weights)
            encrypted_weights_list.append(encrypted_weights)
        
        # 2. æš—å·åŒ–ã•ã‚ŒãŸé‡ã¿ã‚’é›†ç´„
        aggregated_weights = self.fhe_aggregator.aggregate_encrypted_weights(encrypted_weights_list)
        
        # 3. ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ¢ãƒ‡ãƒ«ã‚’æ›´æ–°
        with torch.no_grad():
            for name, param in self.global_model.named_parameters():
                param.copy_(torch.from_numpy(aggregated_weights[name]))
        
        print("ğŸ”’ FHE aggregation completed successfully!")

    def get_global_weights(self):
        weights = {}
        for name, param in self.global_model.named_parameters():
            weights[name] = param.data.cpu().numpy()
        return weights

def main():
    print("=== ğŸ”’ Encrypted Federated Learning with FHE ===")
    
    num_clients = 3
    num_rounds = 3
    
    # FHEå¯¾å¿œã‚µãƒ¼ãƒãƒ¼ã‚’åˆæœŸåŒ–
    server = EncryptedServer(num_clients=num_clients)
    clients = [Client(client_id=i+1, data_seed=i*100) for i in range(num_clients)]
    
    print("\nInitial global model weights:")
    for name, param in server.global_model.named_parameters():
        print(f"  {name}: {param.data}")
    
    print("\nInitial Global Model Evaluation:")
    initial_accuracy, _ = server.evaluate_global_model()
    
    # Federated Learning ã®ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—
    for round_num in range(num_rounds):
        print(f"\n{'='*60}")
        print(f"ğŸ”„ FEDERATED LEARNING ROUND {round_num + 1}/{num_rounds}")
        print(f"{'='*60}")
        
        # ã‚°ãƒ­ãƒ¼ãƒãƒ«é‡ã¿ã‚’å–å¾—
        global_weights = server.get_global_weights()
        
        # å„ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã§ãƒ­ãƒ¼ã‚«ãƒ«å­¦ç¿’
        client_weights_list = []
        client_accuracies = []
        
        for client in clients:
            updated_weights, accuracy = client.local_update(global_weights, epochs=2)
            client_weights_list.append(updated_weights)
            client_accuracies.append(accuracy)
        
        print(f"\nClient accuracies: {[f'{acc:.2f}%' for acc in client_accuracies]}")
        
        # ğŸ”’ FHEã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«é›†ç´„
        server.aggregate_models_with_fhe(client_weights_list)
        
        # ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ¢ãƒ‡ãƒ«è©•ä¾¡
        print(f"\nGlobal Model Evaluation after Round {round_num + 1}:")
        server.evaluate_global_model()
    
    print(f"\n{'='*60}")
    print("ğŸ”’ ENCRYPTED FEDERATED LEARNING COMPLETED!")
    print(f"{'='*60}")
    
    print("\nFinal global model weights:")
    for name, param in server.global_model.named_parameters():
        print(f"  {name}: {param.data}")
    
    print("\nFinal Global Model Evaluation:")
    final_accuracy, _ = server.evaluate_global_model()
    print(f"Overall improvement: {final_accuracy - initial_accuracy:.2f}%")

if __name__ == "__main__":
    main()